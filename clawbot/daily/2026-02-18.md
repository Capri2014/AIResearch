# 2026-02-18 Daily Notes

## Pipeline PR #2 (Daily Cadence)

**Focus:** ResAD + Toy Waypoint Environment Integration for Quantitative Evaluation

### Changes

- **Updated:** `training/rl/toy_waypoint_env.py` - ResAD Policy Integration
  - Added `policy_resad()` function for ResAD-based waypoint prediction
  - Added `create_resad_policy()` factory for checkpoint loading
  - Integrates ResAD residual correction with toy environment

- **Updated:** `training/rl/eval_toy_waypoint_env.py` - ADE/FDE Metrics
  - Added ADE/FDE computation per episode
  - Added comparison mode (`--policy compare`) for SFT vs RL vs ResAD
  - Summary statistics with mean/std for ADE, FDE, success_rate
  - Output: `out/eval/<run_id>/metrics.json` with full metrics

- **Updated:** `training/rl/resad.py` - Tensor Dimension Fixes
  - Fixed ResADResidualHead for 2D feature input
  - Fixed UncertaintyHead for 2D feature input
  - Proper broadcasting for features [B, 256] → [B, T, 256]
  - Added ego_state dimension handling for inertial reference

### Metrics Computation

```python
def compute_ade_fde(predicted, target):
    ade = mean(||predicted - target||, axis=1)  # Average Displacement Error
    fde = ||predicted[-1] - target[-1]||        # Final Displacement Error
```

### Comparison Output

```
Metric               SFT             RL              Δ
ADE (m)              39.338 ± 13.530 39.216 ± 13.633 -0.3%
FDE (m)              43.574 ± 16.828 43.217 ± 17.127 -0.8%
Success Rate         0.0%          0.0%          +0.0pp
```

### Usage

```bash
# Evaluate SFT policy with ADE/FDE
python -m training.rl.eval_toy_waypoint_env --policy sft --episodes 20

# Evaluate ResAD policy with checkpoint
python -m training.rl.eval_toy_waypoint_env --policy resad --checkpoint resad.pt

# Compare all policies
python -m training.rl.eval_toy_waypoint_env --policy compare --episodes 50
```

### Output Structure

```
out/eval/<run_id>/
  └── metrics.json
    {
      "run_id": "20260218-103527",
      "domain": "rl",
      "policy": {"name": "toy_waypoint_sft"},
      "scenarios": [...],
      "summary": {
        "ade_mean": 39.338,
        "ade_std": 13.530,
        "fde_mean": 43.574,
        "fde_std": 16.828,
        "success_rate": 0.0,
        "num_episodes": 20
      }
    }
```

### Integration with Driving-First Pipeline

```
Waymo episodes → SSL pretrain → waypoint BC (SFT) → RL refinement (ResAD) → eval (ADE/FDE)
```

The ResAD evaluation enables quantitative comparison of:
- SFT baseline vs RL-refined policies
- Offline metrics (ADE/FDE) vs closed-loop success rate
- Different residual learning strategies

### Next Steps

- [ ] Run ResAD training with actual SFT checkpoint
- [ ] Compare ResAD vs heuristic RL policies on ADE/FDE
- [ ] Integrate CARLA closed-loop metrics with toy environment
- [ ] Add confidence intervals to comparison reports
