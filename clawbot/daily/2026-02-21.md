# Daily Notes - 2026-02-21

## Pipeline PR #2: GRPO Delta-Waypoint Training

### Summary
Added GRPO (Group Relative Policy Optimization) training for residual delta-waypoint learning after SFT.

### Commits
- `c95df22` - feat(rl): Add GRPO delta-waypoint training for RL refinement after SFT

### New Files
- `training/rl/train_grpo_delta_waypoint.py` - GRPO training script
- `training/rl/test_grpo_delta_smoke.py` - Smoke tests
- `training/rl/sft_checkpoint_loader.py` - SFT checkpoint loading

### Architecture
```
final_waypoints = sft_waypoints + delta_head(z)
```

### Key Features
- Frozen SFT model as base predictor
- Trainable delta head with GRPO optimization
- Group-relative advantage estimation
- Integration with SFT checkpoint loader

### GRPO vs PPO
- GRPO doesn't need a value function
- Better scaling to large models
- Simpler, more stable training

### Usage
```bash
python -m training.rl.train_grpo_delta_waypoint \
  --sft-checkpoint out/waypoint_bc/run_001/model.pt \
  --output-dir out/grpo_delta \
  --num-episodes 1000
```

### PR
- Branch: `feature/daily-2026-02-21-b`
- URL: https://github.com/Capri2014/AIResearch/pull/new/feature/daily-2026-02-21-b
