# 2026-02-15

## What I shipped
- **Waypoint BC eval metrics (ADE/FDE)**: Added `training/sft/eval_waypoint_bc.py` that computes:
  - ADE (Average Displacement Error): mean L2 distance across all waypoint timesteps
  - FDE (Final Displacement Error): L2 distance at the final timestep
  - Outputs `metrics.json` (summary stats) and `predictions.jsonl` (per-frame details)
  - Supports configurable eval subset via `--eval-fraction` for rapid iteration
- **ScenarioRunner output parser**: Added `_parse_srunner_output()` to `sim/driving/carla_srunner/run_srunner_eval.py` that extracts:
  - `route_completion` (fraction 0-1)
  - `collisions`, `offroad`, `red_light` infractions
  - `comfort` metrics (max_accel, max_jerk)
  - Parses both JSON result files (scenario_result.json, results.json) and structured log patterns
- Wired parsed metrics into the main eval loop, populating schema-compatible `metrics.json` with real SR outputs

## Why it matters
- Waypoint BC eval enables quantitative comparison of trained policies against ground truth expert trajectories.
- ADE/FDE metrics are standard benchmarks in motion planning literature.
- Per-frame predictions in `predictions.jsonl` enable error analysis and failure case mining.
- ScenarioRunner metrics enable closed-loop evaluation of policies in simulation.

## Next
- Wire the Torch `WaypointPolicyTorch` into closed-loop ScenarioRunner runs (policy serves waypoints to SR)
- Add `--policy-checkpoint` support for loading trained BC models in ScenarioRunner
- Run waypoint BC eval on trained checkpoints to validate metric extraction
