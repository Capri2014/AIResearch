# Daily Notes: 2026-02-16 (Pipeline PR #2)

## Date
- Monday, February 16th, 2026
- Time: 10:30 AM (America/New_York)

## Pipeline Status
- **Pipeline PR #1**: Merged (Unified Policy Evaluation Framework)
- **Pipeline PR #2**: In progress (Training-Time Metrics for Checkpoint Selection)

## Today's Focus: Evaluation-First Design

Per MEMORY.md guidance: "Add ADE/FDE metrics during training, not after â€” enables checkpoint selection based on quality metrics."

### Completed Today
1. **Created `training/sft/training_metrics.py`**
   - `compute_batch_ade_fde()`: Efficient ADE/FDE computation for batches
   - `TrainingMetricsTracker`: Validation loop integration for training
   - `EpochMetrics`: Structured metrics storage with `to_dict()`
   - `save_checkpoint_with_metrics()`: Checkpoint saving with evaluation results
   - `create_eval_dataloader()`: Fast evaluation dataloader creation

2. **Key Features**
   - Per-batch ADE/FDE computation
   - Automatic best checkpoint tracking
   - Metrics persistence to JSON
   - Support for validation subset (eval_fraction for speed)

### Next Steps
1. Integrate `TrainingMetricsTracker` into `train_waypoint_bc_cot.py`
2. Add checkpoint selection based on best ADE
3. Connect GRPO training to unified evaluation
4. Add CoT trace integration to evaluation

## Notes
- Timezone note: User often schedules in America/Los_Angeles for CL cadence
- Default model: MiniMax-M2.5
- Research tasks: Use survey agent by default

## References
- Eval script: `training/sft/eval_waypoint_bc.py`
- Unified eval: `training/rl/unified_eval.py`
- GRPO impl: `training/rl/grpo_waypoint.py`
