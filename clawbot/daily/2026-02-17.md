# 2026-02-17 Daily Notes

## Pipeline PR #9 (Daily Cadence)

**Focus:** RL Refinement After SFT - Evaluation + Metrics Hardening

### Changes

- **Updated:** `training/rl/eval_toy_waypoint_env.py` - Deterministic evaluation with ADE/FDE
  - Added ADE/FDE computation per episode (core metrics for RL refinement)
  - Tracks car trajectory vs target waypoints
  - Computes summary metrics (mean/std for ADE, FDE, success_rate)
  - Prints 3-line summary report (ADE, FDE, Success Rate)
  - Output: `out/eval/<run_id>/metrics.json` with per-episode and summary metrics

- **Updated:** `data/schema/metrics.json` - Extended schema for RL metrics
  - Added `ade`, `fde` fields to per-scenario metrics
  - Added `summary` object with aggregate statistics
  - Documents return, steps, final_dist fields

### Metrics Schema

```json
{
  "scenarios": [{
    "scenario_id": "seed:0",
    "success": true,
    "ade": 5.23,      // Average Displacement Error (meters)
    "fde": 5.81,      // Final Displacement Error (meters)
    "return": 10.5,   // Episode cumulative reward
    "steps": 42,       // Episode length
    "final_dist": 2.1  // Distance to final target
  }],
  "summary": {
    "ade_mean": 5.27,
    "ade_std": 0.12,
    "fde_mean": 5.83,
    "fde_std": 1.59,
    "success_rate": 0.0,
    "num_episodes": 20
  }
}
```

### Usage

```bash
# Evaluate SFT policy
python -m training.rl.eval_toy_waypoint_env --policy sft --episodes 20 --seed-base 0

# Evaluate RL-refined policy (same seeds for comparison)
python -m training.rl.eval_toy_waypoint_env --policy rl --episodes 20 --seed-base 0

# Output example:
# ADE: 5.27m ± 0.12m (SFT) → 5.19m (RL) [-2%]
# FDE: 5.83m ± 1.59m (SFT) → 5.66m (RL) [-3%]
# Success: 0.0% (SFT) → 0.0% (RL) [+0%]
```

### 3-Line Comparison Report

```
ADE: 5.27m ± 0.12m (SFT) → 5.19m (RL) [-2%]
FDE: 5.83m ± 1.59m (SFT) → 5.66m (RL) [-3%]
Success: 0.0% (SFT) → 0.0% (RL) [+0%]
```

### Pipeline Integration

RL refinement evaluation stage:
```
Waymo episodes → SSL pretrain → waypoint BC (SFT) → RL refinement → eval (ADE/FDE)
```

### Next Steps

- [ ] Run comparison with more episodes (50-100) for statistical significance
- [ ] Add confidence intervals to summary metrics
- [ ] Compare with actual trained RL checkpoint (not just heuristic)

---

## Pipeline PR #8 (Daily Cadence)

**Focus:** CARLA Closed-Loop Waypoint BC Evaluation Script

### Changes

- **Added:** `training/eval/run_carla_closed_loop_eval.py` - Comprehensive closed-loop evaluation
  - WaypointBCModelWrapper for loading trained checkpoints
  - 5 evaluation scenarios: straight_clear, straight_cloudy, straight_night, straight_rain, turn_clear
  - ClosedLoopMetrics: route_completion, collisions, deviation tracking
  - ScenarioResult aggregation with success_rate, avg_route_completion
  - Smoke test for validation without CARLA server

- **Components:**
  - `ScenarioConfig`: weather, map, spawn/target points per scenario
  - `ClosedLoopMetrics`: episode-level closed-loop metrics
  - `ScenarioResult`: aggregated scenario results
  - `WaypointBCModelWrapper`: checkpoint loading and inference
  - `CARLAClosedLoopEvaluator`: vehicle control and episode running

### Pipeline Integration

Complete CARLA evaluation stage:
```
Waymo episodes → SSL pretrain → waypoint BC → CARLA eval
```

### Usage

```bash
# Smoke test (no CARLA required)
python -m training.eval.run_carla_closed_loop_eval --smoke

# Full evaluation with CARLA server
python -m training.eval.run_carla_closed_loop_eval \
  --checkpoint out/waypoint_bc/best_model.pt \
  --output-dir out/carla_closed_loop_eval

# Specific scenarios only
python -m training.eval.run_carla_closed_loop_eval \
  --checkpoint out/waypoint_bc/best_model.pt \
  --output-dir out/carla_eval_night \
  --scenarios straight_night
```

### Next Steps

- [ ] Run CARLA evaluation with trained checkpoint
- [ ] Compare offline ADE/FDE with closed-loop metrics
- [ ] Add collision/offroad detection sensors
